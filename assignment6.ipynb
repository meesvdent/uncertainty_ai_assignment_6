{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfUzxue2v1Av"
      },
      "source": [
        "This assignment mixes understanding the theory seen in class and reading the code of an implementation of the studied algorithms. You will encounter numbered questions while going through the notebook (this file). You will have to hand in the answers to those questions. To this end use the pdf file that you can also find on Toledo and write down your answer in the corresponding boxes.\n",
        "\n",
        "\n",
        "## Note on interactive notebooks\n",
        "\n",
        "Interactive notebooks like this one allow users to interleave code and text in the same place. The notebook is divided into cells, these are either text cells or code cells. Code cells have a little play button next to them (in Googel Collab, other editors have it in a different place). You can run the code in a code cell by simply pressing the play button. The play button becomes visible when hovering with your mouse over a code cell. \n",
        "\n",
        "\n",
        "\n",
        "# **Assignment 6 - Hidden Markov Model**\n",
        "\n",
        "In this assignment we will implement the alpha and beta recursions for hidden Markov models (HMM), which you saw in class and have a look at the Viterbi algorithms, as well. \n",
        "\n",
        "\n",
        "\n",
        "Our HMM will model a student's prepardness. However, we are not able to directly observe whether a student is prepared or not. We can only have a look at their grades and whether they attend class or not:\n",
        "- Knowledgeable on the week's topic [0 = not knowledeable, 1 = partially knowledgeable, 2 = very knowledgeable]\n",
        "This corresponds to the prepardness of a student. We will abreviate this random variale by **K**.\n",
        "- Grade in the weekly assignment [0, 9]; abbreviated  **G**.\n",
        "- Attended the weekly lecture [0 = no, 1 = yes]; describes whether a student attended the class in a specific week or not. Abbreviated by **A**.\n",
        "\n",
        "The **Hidden Markov Model** has now the following structure:\n",
        "$K_t$ is the unobserved or hidden random variable. The observed variables are $G_t$ and $A_t$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIeJdfUtpYk3"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "# **Question 1**\n",
        "\n",
        "\n",
        "**Draw the graphical representation of the HMM with 3 observations!**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyalGazzY_3a"
      },
      "source": [
        "\n",
        "Before we start coding up a model we will import the numpy library; a popular scientific computing library in Python.\n",
        "\n",
        "Press the play button to the left of the cell. It appears when you hover with your mouse above the cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v9_LD-NH9qv_"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTeTGO-sKwjt"
      },
      "source": [
        "## The Model\n",
        "\n",
        "In a first step we will write down the initial state, the transition matrix, and the observation model using numpy arrays (matrices)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDhdIXLKK3N9"
      },
      "source": [
        "### Initial State\n",
        "\n",
        "The initial state describes the initial knowledge of the student before the course starts: $p(K_0=k)$ and $k$ ranges from $0$ to $2$. At time step $0$ we do not have any observations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hElH6pBbLWhy"
      },
      "outputs": [],
      "source": [
        "prob_K = np.array([\n",
        "    [0.25],\n",
        "    [0.50],\n",
        "    [0.25],\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj4aNw5rLvol"
      },
      "source": [
        "Let us make sure that the probabilities sum up to 1:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c6CHHK6sL0Bg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f89fdc1-dc27-4c9a-8ddb-8d7b4021a33c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "np.sum(prob_K)==1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORJ-BMBx964g"
      },
      "source": [
        "### Emission/observation model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRiuchd7-RVI"
      },
      "source": [
        "Let us now define the observation model for the grades given the knowledge of the student. In short: $p(G_t=g|K_t=k)$, where we have $t \\geq 1$, $0\\leq g \\leq 9$, and $0\\leq k \\leq 2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wFxudv3xvwu4"
      },
      "outputs": [],
      "source": [
        "prob_KG = np.array(\n",
        "  [\n",
        "    [0.18, 0.16, 0.15, 0.13, 0.11, 0.09, 0.07, 0.05, 0.04, 0.02], \n",
        "    [0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10], \n",
        "    [0.02, 0.04, 0.05, 0.07, 0.09, 0.11, 0.13, 0.15, 0.16, 0.18], \n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR0hcmNQHKY_"
      },
      "source": [
        "Let us again double check that the probabilities sum up to one.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nD1vwV88HAjR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7734751a-a632-4a03-c3a2-8eba7ac8ca3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "np.sum(prob_KG, axis=1)==1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXOrcoYg_g3o"
      },
      "source": [
        "Similarly, we define the observation model for the probability of attending class given the student's knowledge: $p(A_t=a|K_t=k)$, with $t>0$, $0\\leq a \\leq 1$, and $0\\leq k \\leq 2$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MOKK-eYr-kdT"
      },
      "outputs": [],
      "source": [
        "prob_KA = np.array(\n",
        "  [\n",
        "    [0.75, 0.25], # not knowledgeable students attend the lesson with p = 0.75\n",
        "    [0.50, 0.50], # partially knowledgeable students attend the lesson with p = 0.5\n",
        "    [0.66, 0.34], # very knowledgeable students attend the lesson with p = 0.66\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljj1ozWjHHvQ"
      },
      "source": [
        "...and double checking again..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Er85PvVzHFNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39459ede-fa9d-4a06-cf08-fbfd48c6539e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.sum(prob_KG, axis=1)==1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny2w8QU-VbcS"
      },
      "source": [
        "Because we are going to set up our equation with only a single observation model we will combine both observation model into a single observation model representing the joint observation model (given the knowledge of the student): "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wUL_l8tpP94f"
      },
      "outputs": [],
      "source": [
        "prob_KAG = np.einsum('ka,kg->kag',prob_KA,prob_KG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezZfAjHjVgZx"
      },
      "source": [
        "And we check again  whether the probabilites sum up to 1. Here we need to check for almost identity as the floating point multplications which were performed when combining both observation models introduced small errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OjEFcC-eVgka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4956e4d8-f297-4727-d623-15c233241397"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "np.isclose( np.sum(prob_KAG, axis=(1,2)), 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv7kovvEqtsc"
      },
      "source": [
        "---\n",
        "\n",
        "# **Question 2**\n",
        "\n",
        "**Which conditional probability does the matrix `prob_KAG` encode?**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNOpZTsY-2Gm"
      },
      "source": [
        "\n",
        "\n",
        "### Transition model\n",
        "\n",
        "We also write down the transition model $p(K_t=k_t | K_{t-1}= k_{t-1})$, with $0\\leq k_t \\leq 2$ and also $0\\leq k_{t-1} \\leq 2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zG3kIxsJ-5SA"
      },
      "outputs": [],
      "source": [
        "prob_KK = np.array(\n",
        "  [\n",
        "    [0.5, 0.3, 0.2],\n",
        "    [0.2, 0.5, 0.3],\n",
        "    [0.1, 0.4, 0.5],\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxna_gzSIlIz"
      },
      "source": [
        "Making again sure that the probabilities sum up to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZW4qJpi-IjzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f7951c-7e02-4e41-9779-2e5f47e64742"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "np.sum(prob_KK, axis=1)==1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc7wEedtrV7d"
      },
      "source": [
        "---\n",
        "\n",
        "# **Question 3**\n",
        "\n",
        "**What is the probability of $p(K_t=0| K_{t-1}=1)$?**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu5BESNWJMR5"
      },
      "source": [
        "## Recursions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J18HjFkGJOrw"
      },
      "source": [
        "### The Forward Pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS0PrOIoAbi0"
      },
      "source": [
        "We now code the forward and backward algorithm that you saw in class using numpy array methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OW_gGr1If3bo"
      },
      "outputs": [],
      "source": [
        "def forward(initial, transition, emission, observations):\n",
        "  if not observations:\n",
        "    alpha = initial\n",
        "    return alpha\n",
        "  else:\n",
        "    corrector = emission[(slice(None),) + observations[-1]] #Slide 23 corrector\n",
        "    # dimension: [3]\n",
        "    corrector = np.expand_dims(corrector, 1) # we adjust the dimension here in order to make the matrix multiplications below work\n",
        "    # dimensions: [3] -> [3,1]\n",
        "\n",
        "    alpha_minus1 = forward(initial, transition, emission, observations[:-1]) #this is the recursive part of the forward algorithm: before we can compute the current value we need to forward compute the values from the previous time steps\n",
        "    #dimensions: [3,1]\n",
        "\n",
        "    predictor = transition @ alpha_minus1 #the sum on slide 23 is actually a matrix multiplication, we use the @ to make this happen in numpy\n",
        "    #dimensions: [3,3] times [3,1] -> [3,1]\n",
        "\n",
        "    alpha = corrector * predictor # and we perform a pointwise vector multiplication, multiplying the corresponding elements\n",
        "    #dimensions: [3,1] * [3,1] -> [3,1]\n",
        "\n",
        "    return alpha\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwJe2ySFJVRw"
      },
      "source": [
        "### The Backward Pass\n",
        "\n",
        "The backward pass works quite similarly (slide 24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIBE5jqsJbzm"
      },
      "outputs": [],
      "source": [
        "def backward(transition, emission, observations):\n",
        "  if not observations:\n",
        "    return np.ones(shape=(transition.shape[0], 1))\n",
        "  else:\n",
        "    current_emission = emission[(slice(None),) + observations[0]]\n",
        "    current_emission = np.expand_dims(current_emission, 1)\n",
        "    beta_plus1 = backward(transition, emission, observations[1:])\n",
        "    beta = transition @ (beta_plus1 * current_emission)\n",
        "  return beta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfQfhBnTJcLo"
      },
      "source": [
        "## Filtering and Smoothing\n",
        "With the forward and backward pass ready, we can now do some filtering and smoothing. Let's use the following observations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qqsYqXOLu0y"
      },
      "outputs": [],
      "source": [
        "obs = [(1,6),(1,7),(0,5)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T87ydDjJ8dx"
      },
      "source": [
        "### Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyuEoWZTiVXo"
      },
      "source": [
        "We simply express the filtering function in terms of the forward pass. Note how we perform an extra normalization, as we did not compute the a normalization constant when doing the forward pass. The filtering function returns: $ P(K_t | obs) = P(K_t | A_1, G_1,\\dots, A_t, G_t)$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gZ40T7LBAW7"
      },
      "outputs": [],
      "source": [
        "def filtering(initial, transition, emission, observations):\n",
        "  alpha = forward(initial, transition, emission, observations)\n",
        "  alpha = alpha / np.sum(alpha)\n",
        "  return alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL8NyC-9NpgL"
      },
      "source": [
        "We can now infer the probability of the current hidden state (K) using filtering:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IbnCcNVJoce"
      },
      "outputs": [],
      "source": [
        "# the actual filtering command\n",
        "filtered_state = filtering(initial=prob_K, transition=prob_KK, emission=prob_KAG, observations=obs)\n",
        "# printing the obtained results\n",
        "print(filtered_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8WmKO-g6dHE"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "# **Question 4**\n",
        "\n",
        "\n",
        "**What is the probability $p(K_3=1|obs)?$**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3pGVRtXKBI-"
      },
      "source": [
        "### Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAK0gk7EkBXE"
      },
      "source": [
        "Smoothing works similarly, with an additional argument for specifying the target time step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvWSEtgJBrvS"
      },
      "outputs": [],
      "source": [
        "def smoothing(timestep, initial, transition, emission, observations):\n",
        "  # some checks to make sure that the target time step is within the allowed range\n",
        "  n_observations = len(observations)\n",
        "  assert timestep>0\n",
        "  assert timestep<=n_observations\n",
        "\n",
        "  past_observations = observations[:timestep]\n",
        "  future_observations = observations[timestep:]\n",
        "\n",
        "  alpha = forward(initial, transition, emission, past_observations)\n",
        "  beta = backward(transition, emission, future_observations)\n",
        "\n",
        "  forward_backward = alpha * beta\n",
        "  forward_backward = forward_backward / np.sum(forward_backward)\n",
        "\n",
        "  return forward_backward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EwWaanWsxsP"
      },
      "source": [
        "---\n",
        "\n",
        "# **Question 5**\n",
        "\n",
        "**What is the probability distribution of $p(K_2=k| obs)$?**\n",
        "\n",
        "Use the code cell below to obtain the distribution.\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cK8VxJMdPDT"
      },
      "outputs": [],
      "source": [
        "# write the actual smoothing command (replace the FIXME with the actual code)\n",
        "smoothed_state =  #################################################################################### FIXME #########################################################################################\n",
        "# printing the obtained result\n",
        "print(smoothed_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H7mPXpjKfxC"
      },
      "source": [
        "## The Viterbi Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E7Wb9ZYoFqc"
      },
      "source": [
        "We finally consider the problem of computing the **most likely sequence of hidden states *given* the observations**, implementing the *Viterbi algorithm*:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJWB0VvWtgOV"
      },
      "source": [
        "---\n",
        "\n",
        "# **Question 6**\n",
        "\n",
        "**In the line marked with a huge FIXME comment, use the right numpy function applied to the mu vector in order to get the state in question. Give the line of code in your solution.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZH7hXJ6B6O6"
      },
      "outputs": [],
      "source": [
        "def viterbi_backward(transition, emission, observations):\n",
        "  if not observations:\n",
        "    mu = np.ones(transition.shape[0])\n",
        "    return [mu]\n",
        "  else:\n",
        "    current_emission = emission[(slice(None),) + observations[0]]\n",
        "    current_emission = np.expand_dims(current_emission, 1)\n",
        "    # we make again sure here that the dimesions of the arrays match for the matrix multiplications below\n",
        "\n",
        "    # our recursive call now returns two values, the message mu and the list of most probable states\n",
        "    mus = viterbi_backward(transition, emission, observations[1:])\n",
        "\n",
        "    #we use the mu from the next time (t+1) step to compute the one from the current time step\n",
        "    mu = np.einsum(\"ij,j,j-> ij\", transition, np.squeeze(current_emission), np.squeeze(mus[-1]))\n",
        "    mu = np.max(mu, axis=1) #################################################################################### This should have been the line to FIXME #########################################################################################\n",
        "\n",
        "    mus.append(mu)\n",
        "    return mus\n",
        "\n",
        "def viterbi_forward(initial, transition, emission, observations, mus):\n",
        "  if not observations:\n",
        "    viterbi_state = np.squeeze(initial)*np.squeeze(mus[0])\n",
        "    viterbi_state = np.argmax(viterbi_state)\n",
        "    return [viterbi_state]\n",
        "  else:\n",
        "    corrector = emission[(slice(None),) + observations[-1]] \n",
        "    viterbi_states = viterbi_forward(initial, transition, emission, observations[:-1], mus[:-1])\n",
        "\n",
        "    viterbi_transition = transition[viterbi_states[-1],:]\n",
        "\n",
        "    viterbi_state = np.squeeze(viterbi_transition)*np.squeeze(corrector)*np.squeeze(mus[-1])\n",
        "    viterbi_state = np.argmax(viterbi_state)\n",
        "\n",
        "    viterbi_states.append(viterbi_state)\n",
        "    return viterbi_states\n",
        "\n",
        "\n",
        "def viterbi(initial=prob_K, transition=prob_KK, emission=prob_KAG, observations=obs):\n",
        "  mus = viterbi_backward(transition, emission, observations)\n",
        "  mus = list(reversed(mus))\n",
        "\n",
        "  viterbi_states = viterbi_forward(initial, transition, emission, observations, mus)\n",
        "\n",
        "  return viterbi_states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szKQf9QVk0fn"
      },
      "source": [
        "\n",
        "We will use the following observations to run the Viterbi algorithm:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tffqmAThTHny"
      },
      "outputs": [],
      "source": [
        "viterbi_obs = [(0,3),(1,9),(1,4),(0, 3),(0,9), (0,8), (0, 7), (1, 5), (1, 4), (1, 6)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvriXZ9kuGD7"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "# **Question 7**\n",
        "\n",
        "**What are the most likely hidden states at each time step given the observations `viterbi_obs`?**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVTf-JCpd9pV"
      },
      "outputs": [],
      "source": [
        "# write the actual command for executing viterbi (replace the FIXME with the actual code)\n",
        "most_likely_hidden_state = viterbi(\n",
        "    initial=prob_K,\n",
        "    transition=prob_KK,\n",
        "    emission=prob_KAG,\n",
        "    observations=viterbi_obs\n",
        ") \n",
        "print(most_likely_hidden_state)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "assignment6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}